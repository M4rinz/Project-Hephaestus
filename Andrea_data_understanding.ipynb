{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "by Andrea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoreload\n",
    "\n",
    "Autoreload allows the notebook to dynamically load code: if we update some helper functions *outside* of the notebook, we do not need to reload the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclist_df = pd.read_csv(os.path.join('dataset','cyclists.csv'))\n",
    "races_df = pd.read_csv(os.path.join('dataset','races.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary exploration (just strolling around)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6134, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclist_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_url</th>\n",
       "      <th>name</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bruno-surra</td>\n",
       "      <td>Bruno  Surra</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gerard-rue</td>\n",
       "      <td>Gérard  Rué</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jan-maas</td>\n",
       "      <td>Jan  Maas</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nathan-van-hooydonck</td>\n",
       "      <td>Nathan Van Hooydonck</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jose-felix-parra</td>\n",
       "      <td>José Félix  Parra</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _url                  name  birth_year  weight  height  \\\n",
       "0           bruno-surra          Bruno  Surra      1964.0     NaN     NaN   \n",
       "1            gerard-rue           Gérard  Rué      1965.0    74.0   182.0   \n",
       "2              jan-maas             Jan  Maas      1996.0    69.0   189.0   \n",
       "3  nathan-van-hooydonck  Nathan Van Hooydonck      1995.0    78.0   192.0   \n",
       "4      jose-felix-parra     José Félix  Parra      1997.0    55.0   171.0   \n",
       "\n",
       "   nationality  \n",
       "0        Italy  \n",
       "1       France  \n",
       "2  Netherlands  \n",
       "3      Belgium  \n",
       "4        Spain  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_url            object\n",
       "name            object\n",
       "birth_year       Int64\n",
       "weight         float64\n",
       "height         float64\n",
       "nationality     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some datatypes have to be converted\n",
    "cyclist_df[\"birth_year\"] = pd.to_numeric(cyclist_df[\"birth_year\"], errors='coerce').astype('Int64')\n",
    "\n",
    "cyclist_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process the strings, before I become crazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclist_df[\"name\"] = cyclist_df[\"name\"].apply(lambda nome: ' '.join(nome.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6134 entries, 0 to 6133\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   _url         6134 non-null   object \n",
      " 1   name         6134 non-null   object \n",
      " 2   birth_year   6121 non-null   Int64  \n",
      " 3   weight       3078 non-null   float64\n",
      " 4   height       3143 non-null   float64\n",
      " 5   nationality  6133 non-null   object \n",
      "dtypes: Int64(1), float64(2), object(3)\n",
      "memory usage: 293.7+ KB\n"
     ]
    }
   ],
   "source": [
    "cyclist_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only duplicate values that it makes sense to check are the cyclists' names and identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_url</th>\n",
       "      <th>name</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_url, name, birth_year, weight, height, nationality]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclist_df[cyclist_df[\"_url\"].duplicated(keep=\"first\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicate URLs (i.e. identifiers). There are homonyms though, so one shoud be aware of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_url</th>\n",
       "      <th>name</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>andrea-peron-1</td>\n",
       "      <td>Andrea Peron</td>\n",
       "      <td>1971</td>\n",
       "      <td>70.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>roman-kreuziger-sr</td>\n",
       "      <td>Roman Kreuziger</td>\n",
       "      <td>1965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Czech Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>alessandro-pozzi2</td>\n",
       "      <td>Alessandro Pozzi</td>\n",
       "      <td>1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>roman-kreuziger</td>\n",
       "      <td>Roman Kreuziger</td>\n",
       "      <td>1986</td>\n",
       "      <td>65.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>Czech Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>andrea-peron</td>\n",
       "      <td>Andrea Peron</td>\n",
       "      <td>1988</td>\n",
       "      <td>70.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>antonio-cabello-baena</td>\n",
       "      <td>Antonio Cabello</td>\n",
       "      <td>1990</td>\n",
       "      <td>67.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>jesus-lopez23</td>\n",
       "      <td>Jesús López</td>\n",
       "      <td>1955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>alberto-fernandez-sainz</td>\n",
       "      <td>Alberto Fernández</td>\n",
       "      <td>1981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>antonio-cabello</td>\n",
       "      <td>Antonio Cabello</td>\n",
       "      <td>1956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>sergio-dominguez-rodriguez</td>\n",
       "      <td>Sergio Domínguez</td>\n",
       "      <td>1979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>sergio-dominguez-munoz</td>\n",
       "      <td>Sergio Domínguez</td>\n",
       "      <td>1986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>jesus-lopez-carril</td>\n",
       "      <td>Jesús López</td>\n",
       "      <td>1949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>alberto-fernandez-blanco</td>\n",
       "      <td>Alberto Fernández</td>\n",
       "      <td>1955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>alessandro-pozzi</td>\n",
       "      <td>Alessandro Pozzi</td>\n",
       "      <td>1954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            _url               name  birth_year  weight  \\\n",
       "347               andrea-peron-1       Andrea Peron        1971    70.0   \n",
       "1745          roman-kreuziger-sr    Roman Kreuziger        1965     NaN   \n",
       "2235           alessandro-pozzi2   Alessandro Pozzi        1969     NaN   \n",
       "2601             roman-kreuziger    Roman Kreuziger        1986    65.0   \n",
       "2682                andrea-peron       Andrea Peron        1988    70.0   \n",
       "2862       antonio-cabello-baena    Antonio Cabello        1990    67.0   \n",
       "2939               jesus-lopez23        Jesús López        1955     NaN   \n",
       "2953     alberto-fernandez-sainz  Alberto Fernández        1981     NaN   \n",
       "3238             antonio-cabello    Antonio Cabello        1956     NaN   \n",
       "4917  sergio-dominguez-rodriguez   Sergio Domínguez        1979     NaN   \n",
       "4919      sergio-dominguez-munoz   Sergio Domínguez        1986     NaN   \n",
       "5040          jesus-lopez-carril        Jesús López        1949     NaN   \n",
       "5720    alberto-fernandez-blanco  Alberto Fernández        1955     NaN   \n",
       "5722            alessandro-pozzi   Alessandro Pozzi        1954     NaN   \n",
       "\n",
       "      height     nationality  \n",
       "347    183.0           Italy  \n",
       "1745     NaN  Czech Republic  \n",
       "2235     NaN           Italy  \n",
       "2601   183.0  Czech Republic  \n",
       "2682   178.0           Italy  \n",
       "2862   179.0           Spain  \n",
       "2939     NaN           Spain  \n",
       "2953     NaN           Spain  \n",
       "3238     NaN           Spain  \n",
       "4917     NaN           Spain  \n",
       "4919     NaN           Spain  \n",
       "5040     NaN           Spain  \n",
       "5720     NaN           Spain  \n",
       "5722     NaN           Italy  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclist_df[cyclist_df[\"name\"].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon manual checking, all these cyclists exist, therefore there are no duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6134 entries, 0 to 6133\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   _url         6134 non-null   object \n",
      " 1   name         6134 non-null   object \n",
      " 2   birth_year   6121 non-null   Int64  \n",
      " 3   weight       3078 non-null   float64\n",
      " 4   height       3143 non-null   float64\n",
      " 5   nationality  6133 non-null   object \n",
      "dtypes: Int64(1), float64(2), object(3)\n",
      "memory usage: 293.7+ KB\n"
     ]
    }
   ],
   "source": [
    "cyclist_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null values in the _url column, i.e. 0.00% are missing\n",
      "There are 0 null values in the name column, i.e. 0.00% are missing\n",
      "There are 13 null values in the birth_year column, i.e. 0.21% are missing\n",
      "There are 3056 null values in the weight column, i.e. 49.82% are missing\n",
      "There are 2991 null values in the height column, i.e. 48.76% are missing\n",
      "There are 1 null values in the nationality column, i.e. 0.02% are missing\n"
     ]
    }
   ],
   "source": [
    "n_rows = cyclist_df.shape[0]\n",
    "for col in cyclist_df.columns:\n",
    "    print(f\"There are {n_rows - cyclist_df[col].count()} null values in the {col} column, i.e. {100*(n_rows - cyclist_df[col].count())/n_rows:.2f}% are missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best thing to do would be to integrate this missing data, if possible. We'll see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Races dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589865, 18)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_url</th>\n",
       "      <th>name</th>\n",
       "      <th>points</th>\n",
       "      <th>uci_points</th>\n",
       "      <th>length</th>\n",
       "      <th>climb_total</th>\n",
       "      <th>profile</th>\n",
       "      <th>startlist_quality</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>date</th>\n",
       "      <th>position</th>\n",
       "      <th>cyclist</th>\n",
       "      <th>cyclist_age</th>\n",
       "      <th>is_tarmac</th>\n",
       "      <th>is_cobbled</th>\n",
       "      <th>is_gravel</th>\n",
       "      <th>cyclist_team</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tour-de-france/1978/stage-6</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-05 04:02:24</td>\n",
       "      <td>0</td>\n",
       "      <td>sean-kelly</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>vini-ricordi-pinarello-sidermec-1986</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tour-de-france/1978/stage-6</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-05 04:02:24</td>\n",
       "      <td>1</td>\n",
       "      <td>gerrie-knetemann</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>norway-1987</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tour-de-france/1978/stage-6</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-05 04:02:24</td>\n",
       "      <td>2</td>\n",
       "      <td>rene-bittinger</td>\n",
       "      <td>24.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tour-de-france/1978/stage-6</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-05 04:02:24</td>\n",
       "      <td>3</td>\n",
       "      <td>joseph-bruyere</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>navigare-blue-storm-1993</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tour-de-france/1978/stage-6</td>\n",
       "      <td>Tour de France</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978-07-05 04:02:24</td>\n",
       "      <td>4</td>\n",
       "      <td>sven-ake-nilsson</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>spain-1991</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _url            name  points  uci_points    length  \\\n",
       "0  tour-de-france/1978/stage-6  Tour de France   100.0         NaN  162000.0   \n",
       "1  tour-de-france/1978/stage-6  Tour de France   100.0         NaN  162000.0   \n",
       "2  tour-de-france/1978/stage-6  Tour de France   100.0         NaN  162000.0   \n",
       "3  tour-de-france/1978/stage-6  Tour de France   100.0         NaN  162000.0   \n",
       "4  tour-de-france/1978/stage-6  Tour de France   100.0         NaN  162000.0   \n",
       "\n",
       "   climb_total  profile  startlist_quality  average_temperature  \\\n",
       "0       1101.0      1.0               1241                  NaN   \n",
       "1       1101.0      1.0               1241                  NaN   \n",
       "2       1101.0      1.0               1241                  NaN   \n",
       "3       1101.0      1.0               1241                  NaN   \n",
       "4       1101.0      1.0               1241                  NaN   \n",
       "\n",
       "                  date  position           cyclist  cyclist_age  is_tarmac  \\\n",
       "0  1978-07-05 04:02:24         0        sean-kelly         22.0       True   \n",
       "1  1978-07-05 04:02:24         1  gerrie-knetemann         27.0       True   \n",
       "2  1978-07-05 04:02:24         2    rene-bittinger         24.0       True   \n",
       "3  1978-07-05 04:02:24         3    joseph-bruyere         30.0       True   \n",
       "4  1978-07-05 04:02:24         4  sven-ake-nilsson         27.0       True   \n",
       "\n",
       "   is_cobbled  is_gravel                          cyclist_team  delta  \n",
       "0       False      False  vini-ricordi-pinarello-sidermec-1986    0.0  \n",
       "1       False      False                           norway-1987    0.0  \n",
       "2       False      False                                   NaN    0.0  \n",
       "3       False      False              navigare-blue-storm-1993    0.0  \n",
       "4       False      False                            spain-1991    0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 589865 entries, 0 to 589864\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   _url                 589865 non-null  object \n",
      " 1   name                 589865 non-null  object \n",
      " 2   points               589388 non-null  float64\n",
      " 3   uci_points           251086 non-null  float64\n",
      " 4   length               589865 non-null  float64\n",
      " 5   climb_total          442820 non-null  float64\n",
      " 6   profile              441671 non-null  float64\n",
      " 7   startlist_quality    589865 non-null  int64  \n",
      " 8   average_temperature  29933 non-null   float64\n",
      " 9   date                 589865 non-null  object \n",
      " 10  position             589865 non-null  int64  \n",
      " 11  cyclist              589865 non-null  object \n",
      " 12  cyclist_age          589752 non-null  float64\n",
      " 13  is_tarmac            589865 non-null  bool   \n",
      " 14  is_cobbled           589865 non-null  bool   \n",
      " 15  is_gravel            589865 non-null  bool   \n",
      " 16  cyclist_team         430704 non-null  object \n",
      " 17  delta                589865 non-null  float64\n",
      "dtypes: bool(3), float64(8), int64(2), object(5)\n",
      "memory usage: 69.2+ MB\n"
     ]
    }
   ],
   "source": [
    "races_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 columns with numeric attributes.\n",
      "\t They are: ['points', 'uci_points', 'length', 'climb_total', 'profile', 'startlist_quality', 'average_temperature', 'position', 'cyclist_age', 'delta']\n",
      "\n",
      "There are 8 non-numeric attributes.\n",
      "\t They are: ['_url', 'name', 'date', 'cyclist', 'is_tarmac', 'is_cobbled', 'is_gravel', 'cyclist_team']\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(races_df.select_dtypes(include=\"number\").columns)} columns with numeric attributes.\")\n",
    "print(f\"\\t They are: {[col for col in races_df.select_dtypes(include=\"number\").columns]}\\n\")\n",
    "print(f\"There are {len(races_df.select_dtypes(exclude=\"number\").columns)} non-numeric attributes.\")\n",
    "print(f\"\\t They are: {[col for col in races_df.select_dtypes(exclude=\"number\")]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the Cyclists database, it looks like we don't have to fix the strings here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A little sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I've pretty much nailed the final part. \n",
    "# The [a-z0-9-]+ is a bit rough, but does the job\n",
    "pattern = r\"([a-z0-9-]+)/\\d{4}/(prologue|result|stage-\\d)\"\n",
    "all(races_df['_url'].apply(lambda url: bool(re.match(pattern,url))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all URLs can be described with this pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that comes into my mind is to check if the races are all distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amstel Gold Race\n",
      "Clasica Ciclista San Sebastian\n",
      "Clásica Ciclista San Sebastian\n",
      "Clásica Ciclista San Sebastián\n",
      "Clásica San Sebastián\n",
      "Criterium du Dauphiné\n",
      "Criterium du Dauphiné Libére\n",
      "Critérium du Dauphiné\n",
      "Critérium du Dauphiné Libéré\n",
      "Donostia San Sebastian Klasikoa\n",
      "Dwars door België / À travers la Belgique\n",
      "Dwars door Vlaanderen\n",
      "Dwars door Vlaanderen - A travers la Flandre ME\n",
      "Dwars door Vlaanderen / A travers la Flandre\n",
      "Dwars door Vlaanderen / A travers la Flandre ME\n",
      "E3 BinckBank Classic\n",
      "E3 Harelbeke\n",
      "E3 Prijs Vlaanderen\n",
      "E3 Prijs Vlaanderen - Harelbeke\n",
      "E3 Saxo Bank Classic\n",
      "E3 Saxo Classic\n",
      "E3-Prijs Harelbeke\n",
      "Giro d'Italia\n",
      "Giro di Lombardia\n",
      "Gran Camiño\n",
      "Grand Prix Cycliste de Montréal\n",
      "Grand Prix Cycliste de Quebec\n",
      "Grand Prix Cycliste de Québec\n",
      "Il Lombardia\n",
      "Itzulia Basque Country\n",
      "La Flèche Wallonne\n",
      "La Vuelta ciclista a España\n",
      "Liège - Bastogne - Liège\n",
      "Liège-Bastogne-Liège\n",
      "Milano-Sanremo\n",
      "Monte Paschi Eroica\n",
      "Montepaschi Strade Bianche - Eroica Toscana\n",
      "O Gran Camiño\n",
      "Omloop Het Nieuwsblad ME\n",
      "Omloop Het Volk\n",
      "Omloop Het Volk ME\n",
      "Paris - Nice\n",
      "Paris - Roubaix\n",
      "Paris-Roubaix\n",
      "Record Bank E3 Harelbeke\n",
      "Ronde van Vlaanderen - Tour des Flandres ME\n",
      "Ronde van Vlaanderen / Tour des Flandres\n",
      "Ronde van Vlaanderen / Tour des Flandres ME\n",
      "Strade Bianche\n",
      "Tirreno-Adriatico\n",
      "Tour de France\n",
      "Tour de Romandie\n",
      "Tour de Suisse\n",
      "UAE Tour\n",
      "Volta Ciclista a Catalunya\n",
      "Volta a Catalunya\n",
      "Vuelta Ciclista al País Vasco\n",
      "Vuelta a España\n",
      "Vuelta al País Vasco\n",
      "World Championships - Road Race\n",
      "World Championships ME - Road Race\n"
     ]
    }
   ],
   "source": [
    "race_names = np.sort(races_df['name'].unique())\n",
    "for race in race_names:\n",
    "    print(race)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can already see that there are some suspects here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_same(race1:str, \n",
    "                  race2:str, \n",
    "                  pattern:str=r\"([a-z0-9-]+)/\\d{4}/(prologue|result|stage-\\d)\") -> tuple:\n",
    "    \"\"\"Checks if two names refer to the same race, comparing the name that appears in the \n",
    "    `_url` colon. It uses the regular expression passed as `pattern` to extract the race ID\n",
    "\n",
    "    Args:\n",
    "        race1 (str): name of the first race to compare\n",
    "        race2 (str): name of the second race to compare\n",
    "        pattern (str, optional): The pattern against which to check the URLs. Defaults to r\"([a-z0-9-]+)/\\\\d{4}/(prologue|result|stage-\\\\d)\".\n",
    "\n",
    "    Returns:\n",
    "        tuple: equality (True|False), race1's ID(s), race2's ID(s)\n",
    "    \"\"\"\n",
    "    race1_urls = races_df[races_df['name'] == race1]['_url'].unique()\n",
    "    race2_urls = races_df[races_df['name'] == race2]['_url'].unique()\n",
    "    # Just checks\n",
    "    if len(race1_urls) == 0:\n",
    "        print(f\"The race name {race1} has no corresponding URLs.\\n Are you sure you didn't misspell?\")\n",
    "        return\n",
    "    if len(race2_urls) == 0:\n",
    "        print(f\"The race name {race2} has no corresponding URLs.\\n Are you sure you didn't misspell?\")\n",
    "        return\n",
    "    \n",
    "    # This pattern matches all the races' URLs\n",
    "    #pattern = r\"([a-z0-9-]+)/\\d{4}/(prologue|result|stage-\\d)\"\n",
    "\n",
    "    def extract_race_ID(race_url:str) -> str|None:\n",
    "        match = re.match(pattern,race_url)\n",
    "        if match:\n",
    "            # We target the name of the race\n",
    "            return match.group(1)\n",
    "        return None\n",
    "\n",
    "    race_ID_1 = np.unique(np.array([extract_race_ID(url) for url in race1_urls]))\n",
    "    race_ID_2 = np.unique(np.array([extract_race_ID(url) for url in race2_urls]))\n",
    "\n",
    "    return np.array_equal(race_ID_1,race_ID_2), race_ID_1, race_ID_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `check_if_same` function we can check if two slightly different names actually correspond to the same race, by comparing the first part of the associated `_url` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The races 'Clasica Ciclista San Sebastian' and 'Clásica Ciclista San Sebastian' are actually the same.\n",
      "The races 'Clasica Ciclista San Sebastian' and 'Clásica Ciclista San Sebastián' are actually the same.\n",
      "The races 'Clasica Ciclista San Sebastian' and 'Clásica San Sebastián' are actually the same.\n",
      "The races 'Clasica Ciclista San Sebastian' and 'Donostia San Sebastian Klasikoa' are actually the same.\n",
      "The races 'Clásica Ciclista San Sebastian' and 'Clásica Ciclista San Sebastián' are actually the same.\n",
      "The races 'Clásica Ciclista San Sebastian' and 'Clásica San Sebastián' are actually the same.\n",
      "The races 'Clásica Ciclista San Sebastian' and 'Donostia San Sebastian Klasikoa' are actually the same.\n",
      "The races 'Clásica Ciclista San Sebastián' and 'Clásica San Sebastián' are actually the same.\n",
      "The races 'Clásica Ciclista San Sebastián' and 'Donostia San Sebastian Klasikoa' are actually the same.\n",
      "The races 'Clásica San Sebastián' and 'Donostia San Sebastian Klasikoa' are actually the same.\n",
      "The races 'Criterium du Dauphiné' and 'Criterium du Dauphiné Libére' are actually the same.\n",
      "The races 'Criterium du Dauphiné' and 'Critérium du Dauphiné' are actually the same.\n",
      "The races 'Criterium du Dauphiné' and 'Critérium du Dauphiné Libéré' are actually the same.\n",
      "The races 'Criterium du Dauphiné Libére' and 'Critérium du Dauphiné' are actually the same.\n",
      "The races 'Criterium du Dauphiné Libére' and 'Critérium du Dauphiné Libéré' are actually the same.\n",
      "The races 'Critérium du Dauphiné' and 'Critérium du Dauphiné Libéré' are actually the same.\n",
      "The races 'Dwars door België / À travers la Belgique' and 'Dwars door Vlaanderen' are actually the same.\n",
      "The races 'Dwars door België / À travers la Belgique' and 'Dwars door Vlaanderen - A travers la Flandre ME' are actually the same.\n",
      "The races 'Dwars door België / À travers la Belgique' and 'Dwars door Vlaanderen / A travers la Flandre' are actually the same.\n",
      "The races 'Dwars door België / À travers la Belgique' and 'Dwars door Vlaanderen / A travers la Flandre ME' are actually the same.\n",
      "The races 'Dwars door Vlaanderen' and 'Dwars door Vlaanderen - A travers la Flandre ME' are actually the same.\n",
      "The races 'Dwars door Vlaanderen' and 'Dwars door Vlaanderen / A travers la Flandre' are actually the same.\n",
      "The races 'Dwars door Vlaanderen' and 'Dwars door Vlaanderen / A travers la Flandre ME' are actually the same.\n",
      "The races 'Dwars door Vlaanderen - A travers la Flandre ME' and 'Dwars door Vlaanderen / A travers la Flandre' are actually the same.\n",
      "The races 'Dwars door Vlaanderen - A travers la Flandre ME' and 'Dwars door Vlaanderen / A travers la Flandre ME' are actually the same.\n",
      "The races 'Dwars door Vlaanderen / A travers la Flandre' and 'Dwars door Vlaanderen / A travers la Flandre ME' are actually the same.\n",
      "The races 'E3 BinckBank Classic' and 'E3 Harelbeke' are actually the same.\n",
      "The races 'E3 BinckBank Classic' and 'E3 Prijs Vlaanderen' are actually the same.\n",
      "The races 'E3 BinckBank Classic' and 'E3 Prijs Vlaanderen - Harelbeke' are actually the same.\n",
      "The races 'E3 BinckBank Classic' and 'E3 Saxo Bank Classic' are actually the same.\n",
      "The races 'E3 BinckBank Classic' and 'E3 Saxo Classic' are actually the same.\n",
      "The races 'E3 BinckBank Classic' and 'E3-Prijs Harelbeke' are actually the same.\n",
      "The races 'E3 BinckBank Classic' and 'Record Bank E3 Harelbeke' are actually the same.\n",
      "The races 'E3 Harelbeke' and 'E3 Prijs Vlaanderen' are actually the same.\n",
      "The races 'E3 Harelbeke' and 'E3 Prijs Vlaanderen - Harelbeke' are actually the same.\n",
      "The races 'E3 Harelbeke' and 'E3 Saxo Bank Classic' are actually the same.\n",
      "The races 'E3 Harelbeke' and 'E3 Saxo Classic' are actually the same.\n",
      "The races 'E3 Harelbeke' and 'E3-Prijs Harelbeke' are actually the same.\n",
      "The races 'E3 Harelbeke' and 'Record Bank E3 Harelbeke' are actually the same.\n",
      "The races 'E3 Prijs Vlaanderen' and 'E3 Prijs Vlaanderen - Harelbeke' are actually the same.\n",
      "The races 'E3 Prijs Vlaanderen' and 'E3 Saxo Bank Classic' are actually the same.\n",
      "The races 'E3 Prijs Vlaanderen' and 'E3 Saxo Classic' are actually the same.\n",
      "The races 'E3 Prijs Vlaanderen' and 'E3-Prijs Harelbeke' are actually the same.\n",
      "The races 'E3 Prijs Vlaanderen' and 'Record Bank E3 Harelbeke' are actually the same.\n",
      "The races 'E3 Prijs Vlaanderen - Harelbeke' and 'E3 Saxo Bank Classic' are actually the same.\n",
      "The races 'E3 Prijs Vlaanderen - Harelbeke' and 'E3 Saxo Classic' are actually the same.\n",
      "The races 'E3 Prijs Vlaanderen - Harelbeke' and 'E3-Prijs Harelbeke' are actually the same.\n",
      "The races 'E3 Prijs Vlaanderen - Harelbeke' and 'Record Bank E3 Harelbeke' are actually the same.\n",
      "The races 'E3 Saxo Bank Classic' and 'E3 Saxo Classic' are actually the same.\n",
      "The races 'E3 Saxo Bank Classic' and 'E3-Prijs Harelbeke' are actually the same.\n",
      "The races 'E3 Saxo Bank Classic' and 'Record Bank E3 Harelbeke' are actually the same.\n",
      "The races 'E3 Saxo Classic' and 'E3-Prijs Harelbeke' are actually the same.\n",
      "The races 'E3 Saxo Classic' and 'Record Bank E3 Harelbeke' are actually the same.\n",
      "The races 'E3-Prijs Harelbeke' and 'Record Bank E3 Harelbeke' are actually the same.\n",
      "The races 'Giro di Lombardia' and 'Il Lombardia' are actually the same.\n",
      "The races 'Gran Camiño' and 'O Gran Camiño' are actually the same.\n",
      "The races 'Grand Prix Cycliste de Quebec' and 'Grand Prix Cycliste de Québec' are actually the same.\n",
      "The races 'Itzulia Basque Country' and 'Vuelta Ciclista al País Vasco' are actually the same.\n",
      "The races 'Itzulia Basque Country' and 'Vuelta al País Vasco' are actually the same.\n",
      "The races 'La Vuelta ciclista a España' and 'Vuelta a España' are actually the same.\n",
      "The races 'Liège - Bastogne - Liège' and 'Liège-Bastogne-Liège' are actually the same.\n",
      "The races 'Monte Paschi Eroica' and 'Montepaschi Strade Bianche - Eroica Toscana' are actually the same.\n",
      "The races 'Monte Paschi Eroica' and 'Strade Bianche' are actually the same.\n",
      "The races 'Montepaschi Strade Bianche - Eroica Toscana' and 'Strade Bianche' are actually the same.\n",
      "The races 'Omloop Het Nieuwsblad ME' and 'Omloop Het Volk' are actually the same.\n",
      "The races 'Omloop Het Nieuwsblad ME' and 'Omloop Het Volk ME' are actually the same.\n",
      "The races 'Omloop Het Volk' and 'Omloop Het Volk ME' are actually the same.\n",
      "The races 'Paris - Roubaix' and 'Paris-Roubaix' are actually the same.\n",
      "The races 'Ronde van Vlaanderen - Tour des Flandres ME' and 'Ronde van Vlaanderen / Tour des Flandres' are actually the same.\n",
      "The races 'Ronde van Vlaanderen - Tour des Flandres ME' and 'Ronde van Vlaanderen / Tour des Flandres ME' are actually the same.\n",
      "The races 'Ronde van Vlaanderen / Tour des Flandres' and 'Ronde van Vlaanderen / Tour des Flandres ME' are actually the same.\n",
      "The races 'Volta Ciclista a Catalunya' and 'Volta a Catalunya' are actually the same.\n",
      "The races 'Vuelta Ciclista al País Vasco' and 'Vuelta al País Vasco' are actually the same.\n",
      "The races 'World Championships - Road Race' and 'World Championships ME - Road Race' are actually the same.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store pairs of races that are actually the same\n",
    "same_races = []\n",
    "\n",
    "# Iterate through all pairs of race names\n",
    "for i in range(len(race_names)):\n",
    "    for j in range(i + 1, len(race_names)):\n",
    "        race1 = race_names[i]\n",
    "        race2 = race_names[j]\n",
    "        # Use the check_if_same function to compare the races\n",
    "        try:\n",
    "            same = check_if_same(race1, race2)[0]\n",
    "            if same:\n",
    "                same_races.append((race1, race2))\n",
    "        except TypeError:\n",
    "            print(f\"Caught error at races {race_names[i]} and {race_names[j]}\")\n",
    "        \n",
    "\n",
    "# Print the pairs of races that are actually the same\n",
    "for race1, race2 in same_races:\n",
    "    print(f\"The races '{race1}' and '{race2}' are actually the same.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't trust the following sentence!\n",
      "Allegedly, there are 37.0 races that are the same, out of 61 possible\n"
     ]
    }
   ],
   "source": [
    "print(\"Don't trust the following sentence!\")\n",
    "print(f\"Allegedly, there are {len(same_races)/2} races that are the same, out of {len(race_names)} possible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like many races are the same, but they changed name between years. To have the confirmation, one should check the data more carefully considering multiple sources, of course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Amstel Gold Race                      [amstel-gold-race/2018/result, amstel-gold-rac...\n",
       "Clasica Ciclista San Sebastian        [san-sebastian/2016/result, san-sebastian/2006...\n",
       "Clásica Ciclista San Sebastian                              [san-sebastian/2017/result]\n",
       "Clásica Ciclista San Sebastián        [san-sebastian/2019/result, san-sebastian/1990...\n",
       "Clásica San Sebastián                 [san-sebastian/1981/result, san-sebastian/1982...\n",
       "                                                            ...                        \n",
       "Vuelta Ciclista al País Vasco         [itzulia-basque-country/2012/stage-1, itzulia-...\n",
       "Vuelta a España                       [vuelta-a-espana/2016/stage-14, vuelta-a-espan...\n",
       "Vuelta al País Vasco                  [itzulia-basque-country/2007/stage-3, itzulia-...\n",
       "World Championships - Road Race       [world-championship/1996/result, world-champio...\n",
       "World Championships ME - Road Race    [world-championship/2002/result, world-champio...\n",
       "Name: _url, Length: 61, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races_df.groupby(\"name\")['_url'].unique()#.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 589865 entries, 0 to 589864\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   _url                 589865 non-null  object \n",
      " 1   name                 589865 non-null  object \n",
      " 2   points               589388 non-null  float64\n",
      " 3   uci_points           251086 non-null  float64\n",
      " 4   length               589865 non-null  float64\n",
      " 5   climb_total          442820 non-null  float64\n",
      " 6   profile              441671 non-null  float64\n",
      " 7   startlist_quality    589865 non-null  int64  \n",
      " 8   average_temperature  29933 non-null   float64\n",
      " 9   date                 589865 non-null  object \n",
      " 10  position             589865 non-null  int64  \n",
      " 11  cyclist              589865 non-null  object \n",
      " 12  cyclist_age          589752 non-null  float64\n",
      " 13  is_tarmac            589865 non-null  bool   \n",
      " 14  is_cobbled           589865 non-null  bool   \n",
      " 15  is_gravel            589865 non-null  bool   \n",
      " 16  cyclist_team         430704 non-null  object \n",
      " 17  delta                589865 non-null  float64\n",
      "dtypes: bool(3), float64(8), int64(2), object(5)\n",
      "memory usage: 69.2+ MB\n"
     ]
    }
   ],
   "source": [
    "races_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null values in the _url column, i.e. 0.00% are missing\n",
      "There are 0 null values in the name column, i.e. 0.00% are missing\n",
      "There are 477 null values in the points column, i.e. 0.08% are missing\n",
      "There are 338779 null values in the uci_points column, i.e. 57.43% are missing\n",
      "There are 0 null values in the length column, i.e. 0.00% are missing\n",
      "There are 147045 null values in the climb_total column, i.e. 24.93% are missing\n",
      "There are 148194 null values in the profile column, i.e. 25.12% are missing\n",
      "There are 0 null values in the startlist_quality column, i.e. 0.00% are missing\n",
      "There are 559932 null values in the average_temperature column, i.e. 94.93% are missing\n",
      "There are 0 null values in the date column, i.e. 0.00% are missing\n",
      "There are 0 null values in the position column, i.e. 0.00% are missing\n",
      "There are 0 null values in the cyclist column, i.e. 0.00% are missing\n",
      "There are 113 null values in the cyclist_age column, i.e. 0.02% are missing\n",
      "There are 0 null values in the is_tarmac column, i.e. 0.00% are missing\n",
      "There are 0 null values in the is_cobbled column, i.e. 0.00% are missing\n",
      "There are 0 null values in the is_gravel column, i.e. 0.00% are missing\n",
      "There are 159161 null values in the cyclist_team column, i.e. 26.98% are missing\n",
      "There are 0 null values in the delta column, i.e. 0.00% are missing\n"
     ]
    }
   ],
   "source": [
    "n_rows = races_df.shape[0]\n",
    "for col in races_df.columns:\n",
    "    print(f\"There are {n_rows - races_df[col].count()} null values in the {col} column, i.e. {100*(n_rows - races_df[col].count())/n_rows:.2f}% are missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe some missing values can be integrated from other sources. Who knows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm curious to check if some stages/tracks have multiple terrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a new feature with just the race name and its stage. This is to \"isolate\" the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name_stage(url:str,\n",
    "              pattern:str=r\"([a-z0-9-]+)/\\d{4}/(prologue|result|stage-\\d)\") -> str:\n",
    "    match = re.match(pattern,url)\n",
    "    if match:\n",
    "        return f\"{match.group(1)}_{match.group(2)}\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "races_df_copy = pd.DataFrame.copy(races_df)\n",
    "\n",
    "races_df_copy[\"name_stage\"] = races_df_copy[\"_url\"].apply(extract_name_stage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I group the dataframe based on this new column, and get the unique values for `is_X`, for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_tarmac</th>\n",
       "      <th>is_cobbled</th>\n",
       "      <th>is_gravel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_stage</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amstel-gold-race_result</th>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dauphine_prologue</th>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dauphine_stage-1</th>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dauphine_stage-2</th>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dauphine_stage-3</th>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vuelta-a-espana_stage-6</th>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vuelta-a-espana_stage-7</th>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vuelta-a-espana_stage-8</th>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vuelta-a-espana_stage-9</th>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world-championship_result</th>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          is_tarmac is_cobbled is_gravel\n",
       "name_stage                                              \n",
       "amstel-gold-race_result     [False]    [False]   [False]\n",
       "dauphine_prologue            [True]    [False]   [False]\n",
       "dauphine_stage-1             [True]    [False]   [False]\n",
       "dauphine_stage-2             [True]    [False]   [False]\n",
       "dauphine_stage-3             [True]    [False]   [False]\n",
       "...                             ...        ...       ...\n",
       "vuelta-a-espana_stage-6      [True]    [False]   [False]\n",
       "vuelta-a-espana_stage-7      [True]    [False]   [False]\n",
       "vuelta-a-espana_stage-8      [True]    [False]   [False]\n",
       "vuelta-a-espana_stage-9      [True]    [False]   [False]\n",
       "world-championship_result   [False]    [False]   [False]\n",
       "\n",
       "[118 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrain_grouped_data = races_df_copy.groupby('name_stage').agg({'is_tarmac': 'unique',\n",
    "                                                                'is_cobbled': 'unique',\n",
    "                                                                'is_gravel': 'unique'})\n",
    "terrain_grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 118 (unique) \"atomic competitions\", 103 have tarmac\n",
      "Out of 118 (unique) \"atomic competitions\", 0 have cobbled\n",
      "Out of 118 (unique) \"atomic competitions\", 0 have gravel\n"
     ]
    }
   ],
   "source": [
    "def count_n_terrains(terrain:str) -> int:\n",
    "    try:\n",
    "        n = terrain_grouped_data[f'is_{terrain}'].apply(lambda lista: lista[0]).sum()\n",
    "        return n\n",
    "    except KeyError:\n",
    "        print(f\"terrain value {terrain} is invalid.\")\n",
    "        print(\"Only options are 'tarmac', 'cobbled', 'gravel'\")\n",
    "\n",
    "for terrain in ['tarmac', 'cobbled','gravel']:\n",
    "    print(f'Out of {terrain_grouped_data.shape[0]} (unique) \"atomic competitions\", {count_n_terrains(terrain)} have {terrain}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is highly suspicious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the big dataframe, out of 589865, 536042 have tarmac\n",
      "In the big dataframe, out of 589865, 0 have cobbled\n",
      "In the big dataframe, out of 589865, 0 have gravel\n"
     ]
    }
   ],
   "source": [
    "for terrain in ['tarmac', 'cobbled','gravel']:\n",
    "    n = races_df[f'is_{terrain}'].sum()\n",
    "    print(f\"In the big dataframe, out of {races_df.shape[0]}, {n} have {terrain}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the same race has been given different values for the presence of some terrain (maybe because of errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def check_consistent_terrain(terrain:str) -> bool:\n",
    "    try:\n",
    "        # We check if there is only one value (either True or False)\n",
    "        biglist = terrain_grouped_data[f'is_{terrain}'].apply(lambda lista: bool(len(lista)==1))\n",
    "        return all(biglist)\n",
    "    except KeyError:\n",
    "        print(f\"terrain value {terrain} is invalid.\")\n",
    "        print(\"Only options are 'tarmac', 'cobbled', 'gravel'\")\n",
    "\n",
    "for terrain in ['tarmac', 'cobbled','gravel']:\n",
    "    print(check_consistent_terrain(terrain))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it's not the case. This means that the same \"atomic competitions\" (i.e. stages, or subdivisions in general) of the same race have been given the same terrain over the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find the races that have more than one terrain (if there are any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group amstel-gold-race_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group dwars-door-vlaanderen_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group e3-harelbeke_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group gp-montreal_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group gp-quebec_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group il-lombardia_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group la-fleche-wallone_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group liege-bastogne-liege_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group milano-sanremo_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group omloop-het-nieuwsblad_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group paris-roubaix_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group ronde-van-vlaanderen_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group san-sebastian_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group strade-bianche_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n",
      "Group world-championship_result has no terrains\n",
      "is_tarmac     [False]\n",
      "is_cobbled    [False]\n",
      "is_gravel     [False]\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_terrain_races, multiple_terrain_races = [], []\n",
    "\n",
    "for group_key, group_df in races_df_copy.groupby('name_stage'):\n",
    "    terrains = group_df[['is_tarmac','is_cobbled','is_gravel']].agg({'is_tarmac': 'unique',\n",
    "                                                                'is_cobbled': 'unique',\n",
    "                                                                'is_gravel': 'unique'})\n",
    "    if terrains.sum() == 0:\n",
    "        print(f\"Group {group_key} has no terrains\")\n",
    "        print(terrains)\n",
    "        print()\n",
    "        no_terrain_races.append(group_key)\n",
    "    elif terrains.sum() in [2,3]:\n",
    "        print(f\"Group {group_key} has multiple terrains\")\n",
    "        print(terrains)\n",
    "        print()\n",
    "        multiple_terrain_races.append(group_key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Races with no terrain: ['amstel-gold-race_result', 'dwars-door-vlaanderen_result', 'e3-harelbeke_result', 'gp-montreal_result', 'gp-quebec_result', 'il-lombardia_result', 'la-fleche-wallone_result', 'liege-bastogne-liege_result', 'milano-sanremo_result', 'omloop-het-nieuwsblad_result', 'paris-roubaix_result', 'ronde-van-vlaanderen_result', 'san-sebastian_result', 'strade-bianche_result', 'world-championship_result']\n",
      "Races with multiple terrains: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Races with no terrain: {no_terrain_races}\")\n",
    "print(f\"Races with multiple terrains: {multiple_terrain_races}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLT-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
