{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density-based clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for the density-based clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoreload\n",
    "\n",
    "Autoreload allows the notebook to dynamically load code: if we update some helper functions *outside* of the notebook, we do not need to reload the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import procyclingstats as pcs\n",
    "# Base libraries\n",
    "import os\n",
    "import sys\n",
    "# Basic data manipulation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "\n",
    "# Otherwise nothing will be found\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "#sys.path.append('../dataset/')\n",
    "#sys.path.append('../utility/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = os.path.join('Images', 'Clustering_imgs', 'density_based_imgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports from our utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility.overall_utilities import save_plot\n",
    "#from utility.cluster_utility import scale_data, hier_search, get_average_cyclist_per_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read the datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclist_df = pd.read_csv(os.path.join('..','dataset','cyclists_cleaned.csv'))\n",
    "races_df = pd.read_csv(os.path.join('..','dataset','races_cleaned.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyclist_df columns:\n",
      "Index(['_url', 'name', 'birth_year', 'weight', 'height', 'nationality', 'bmi',\n",
      "       'race_count', 'experience_level', 'total_points', 'victories_by_points',\n",
      "       'avg_points_per_race', 'average_position', 'avg_speed_cyclist',\n",
      "       'cyclist_age', 'mean_stamina_index'],\n",
      "      dtype='object')\n",
      "\n",
      "races_df columns:\n",
      "Index(['_url', 'name', 'stage', 'stage_type', 'points', 'uci_points', 'length',\n",
      "       'climb_total', 'profile', 'startlist_quality', 'date', 'position',\n",
      "       'cyclist', 'cyclist_age', 'is_tarmac', 'delta', 'time', 'time_seconds',\n",
      "       'average_speed', 'steepness', 'season', 'is_staged', 'race_country',\n",
      "       'norm_points', 'age_performance_index', 'quality_adjusted_points',\n",
      "       'normalized_length', 'normalized_quality', 'normalized_steepness',\n",
      "       'normalized_time', 'stamina_index'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"cyclist_df columns:\")\n",
    "print(cyclist_df.columns)\n",
    "print()\n",
    "print(\"races_df columns:\")\n",
    "print(races_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I already know that some columns won't be used a priori. Let's remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cyclist_df.drop(columns=[''], inplace=True)\n",
    "races_df.drop(columns=['is_tarmac','norm_points','age_performance_index',\n",
    "\t\t\t\t\t   'average_speed',\n",
    "\t\t\t\t\t   'normalized_length','normalized_quality','normalized_steepness',\n",
    "\t\t\t\t\t   'normalized_time','stamina_index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
