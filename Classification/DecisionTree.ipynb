{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a new notebook because the one with XGBoost was requiring too much ram, this one is built not to study the model but to be compared with the FBT in terms of f1 scores\n",
    "\n",
    "#NONOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "100.00%  \n"
     ]
    }
   ],
   "source": [
    "# just to be shure we will retrain the final model\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from itertools import product #for grid search\n",
    "from sklearn.tree import DecisionTreeClassifier # for classification\n",
    "from tqdm import tqdm # for progress bar\n",
    "from sklearn.metrics import classification_report, f1_score # for evaluation\n",
    "from utility.classification_utility import make_dataset_for_classification\n",
    "from imblearn.over_sampling import RandomOverSampler # for oversampling\n",
    "import json\n",
    "f1_macro = lambda x, y: f1_score(x, y, average='macro') # for our evaluation\n",
    "\n",
    "cyc_path = '../dataset/cyclists_cleaned.csv'\n",
    "races_path = '../dataset/races_cleaned.csv'\n",
    "print('Loading data...')\n",
    "dataset = make_dataset_for_classification(races_df=races_path, cyclists_df=cyc_path)\n",
    "\n",
    "TO_USE_COLS = [\n",
    "    # over time\n",
    "    'total_points', 'avg_points_per_race', \n",
    "    'average_position', 'avg_speed_cyclist',\n",
    "    'race_count',\n",
    "    'average_position_var',\n",
    "    # race related\n",
    "    'profile', \n",
    "    'startlist_quality', 'cyclist_age_rac', 'steepness', \n",
    "    'partecipants_number',\n",
    "    # cyclist related\n",
    "    'bmi',\n",
    "]\n",
    "\n",
    "tr_data = dataset[(dataset['date'] < '2019-01-01') & (dataset['date'] >= '1996-01-01')]\n",
    "tr_out = tr_data['target']\n",
    "tr_data = tr_data[TO_USE_COLS]\n",
    "\n",
    "val_data = dataset[(dataset['date'] >= '2019-01-01') & (dataset['date'] < '2022-01-01')]\n",
    "val_out = val_data['target']\n",
    "val_data = val_data[TO_USE_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'monotonic_cst', 'random_state', 'splitter'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    37243\n",
       "True      6237\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_out.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid search: 100%|\u001b[32m██████████\u001b[0m| 8/8 [00:24<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "max_depths = [5, 10, 15, 20]\n",
    "min_samples_splits = [2, 5, 10, 25]\n",
    "min_samples_leafs = [1, 2, 4, 8, 16, 32]\n",
    "criterions = ['gini', 'entropy']\n",
    "class_weights = ['balanced', {0: 1, 1: 2}, {0: 1, 1: 4}, {0: 1, 1: 6}]\n",
    "\n",
    "#max_depths = [5, 10]\n",
    "#min_samples_splits = [2, 5]\n",
    "#min_samples_leafs = [1, 2]\n",
    "#criterions = ['entropy']\n",
    "#class_weights = [{0: 1, 1: 4}]\n",
    "\n",
    "params = list(product(max_depths, min_samples_splits, min_samples_leafs, criterions, class_weights))\n",
    "\n",
    "results = []\n",
    "for param in tqdm(params, total=len(params), desc='Grid search', colour='green', smoothing=0.1):\n",
    "    max_depth, min_samples_split, min_samples_leaf, criterion, class_weight = param\n",
    "    clf = DecisionTreeClassifier(\n",
    "        max_depth=max_depth, \n",
    "        min_samples_split=min_samples_split, \n",
    "        min_samples_leaf=min_samples_leaf, \n",
    "        criterion=criterion,\n",
    "        class_weight=class_weight,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(tr_data, tr_out)\n",
    "    tr_pred = clf.predict(tr_data)\n",
    "    val_pred = clf.predict(val_data)\n",
    "    results.append({\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'criterion': criterion,\n",
    "        'class_weight': class_weight,\n",
    "        'tr_f1_macro': f1_macro(tr_out, tr_pred),\n",
    "        'val_f1_macro': f1_macro(val_out, val_pred),\n",
    "        'tr_report': classification_report(tr_out, tr_pred, output_dict=True),\n",
    "        'val_report': classification_report(val_out, val_pred, output_dict=True)\n",
    "    })\n",
    "\n",
    "with open('DTree_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'criterion': 'entropy',\n",
       " 'class_weight': {'0': 1, '1': 4},\n",
       " 'tr_f1_macro': 0.6332986370679715,\n",
       " 'val_f1_macro': 0.6568971047681522}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('DTree_results.json', 'w') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "best = max(results, key=lambda x: x['val_f1_macro'])\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
