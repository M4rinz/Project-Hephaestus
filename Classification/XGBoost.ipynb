{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As always we start by importing the necessary libraries\n",
    "# and loading the data we will be working with. (at this point I'm importing stuff just for the fun of it)\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utility.classification_utility import *\n",
    "\n",
    "# we define a random state to make the results reproducible\n",
    "RANDOM_STATE = 42\n",
    "RUN_SLOW_STUFF = True\n",
    "\n",
    "cyc = '../dataset/cyclists_cleaned.csv'\n",
    "races = '../dataset/races_cleaned.csv'\n",
    "\n",
    "full_df = get_merged_dataset(cyc, races)\n",
    "full_df = define_target(full_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points: 425399\n",
      "position: 0\n",
      "average_speed: 0\n",
      "stamina_index: 137267\n"
     ]
    }
   ],
   "source": [
    "#full_df = define_target(full_df)\n",
    "full_df[['points', 'position', 'average_speed', 'stamina_index']]\n",
    "print('points:', full_df['points'].isna().sum())\n",
    "print('position:',full_df['position'].isna().sum())\n",
    "print('average_speed:',full_df['average_speed'].isna().sum())\n",
    "print('stamina_index:',full_df['stamina_index'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_url_rac', 'name_rac', 'stage', 'stage_type', 'points', 'uci_points',\n",
       "       'length', 'climb_total', 'profile', 'startlist_quality', 'date',\n",
       "       'position', 'cyclist', 'cyclist_age_rac', 'is_tarmac', 'delta', 'time',\n",
       "       'time_seconds', 'average_speed', 'steepness', 'season', 'is_staged',\n",
       "       'race_country', 'norm_points', 'age_performance_index',\n",
       "       'quality_adjusted_points', 'normalized_length', 'normalized_quality',\n",
       "       'normalized_steepness', 'normalized_time', 'stamina_index', '_url_cyc',\n",
       "       'name_cyc', 'birth_year', 'weight', 'height', 'nationality', 'bmi',\n",
       "       'race_count', 'experience_level', 'total_points', 'victories_by_points',\n",
       "       'avg_points_per_race', 'average_position', 'avg_speed_cyclist',\n",
       "       'cyclist_age_cyc', 'mean_stamina_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from random import shuffle\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../..'))\n",
    "\n",
    "from xgboost import XGBClassifier # XGBoost classifier\n",
    "from time import time # to compute time\n",
    "from itertools import product #for grid search\n",
    "from tqdm import tqdm # for progress bar\n",
    "from sklearn.metrics import classification_report, f1_score # for evaluation\n",
    "from utilsData import dataset_loader, load_data # for loading data\n",
    "from imblearn.over_sampling import RandomOverSampler # for oversampling\n",
    "f1_macro = lambda x, y: f1_score(x, y, average='macro') # for our evaluation\n",
    "\n",
    "folderName = f'./Datasets/Cleaned_Dataset_{years_to_death}Y/chl_dataset_known.csv'\n",
    "\n",
    "# TODO: complete gridsearch adding various sampling strategies\n",
    "oversample = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "tr_data, tr_out = oversample.fit_resample(tr_data, tr_out)\n",
    "\n",
    "# Hyperparameters\n",
    "N_estimators = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400]\n",
    "Learning_rate = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "# Shuffle hyperparameters\n",
    "hyperparameters = list(product(N_estimators, Learning_rate))\n",
    "shuffle(hyperparameters)\n",
    "\n",
    "# Grid search\n",
    "best_score = 0\n",
    "best_params = None\n",
    "for n_estimators, learning_rate in tqdm(hyperparameters, total=len(hyperparameters)):\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        learning_rate=learning_rate, \n",
    "        n_jobs=-1, \n",
    "        random_state=42,\n",
    "        objective='binary:logistic'\n",
    "    )\n",
    "    xgb_model.fit(tr_data, tr_out)\n",
    "    val_pred = xgb_model.predict(val_data)\n",
    "    score = f1_macro(val_out, val_pred)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = (n_estimators, learning_rate)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "n_estimators, learning_rate = best_params\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=n_estimators, \n",
    "    learning_rate=learning_rate, \n",
    "    n_jobs=-1, \n",
    "    random_state=42,\n",
    "    objective='binary:logistic'\n",
    ")\n",
    "xgb_model.fit(tr_data, tr_out)\n",
    "\n",
    "# Predict\n",
    "val_pred = xgb_model.predict(val_data)\n",
    "print(f'val f1-score: {f1_macro(val_out, val_pred)}')\n",
    "print(classification_report(val_out, val_pred))\n",
    "print(f'Best hyperparameters: {best_params}')\n",
    "print(f'Best score: {best_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
