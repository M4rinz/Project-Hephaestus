Parameters: {'optimizer': 'sgd', 'num_units': 64, 'num_layers': 1, 'epochs': 5, 'batch_size': 16, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.88      0.98      0.93     37243
        True       0.59      0.17      0.27      6237

    accuracy                           0.86     43480
   macro avg       0.73      0.58      0.60     43480
weighted avg       0.83      0.86      0.83     43480




Parameters: {'optimizer': 'lion', 'num_units': 32, 'num_layers': 1, 'epochs': 5, 'batch_size': 64, 'activation': 'tanh'}
              precision    recall  f1-score   support

       False       0.88      0.98      0.92     37243
        True       0.59      0.16      0.26      6237

    accuracy                           0.86     43480
   macro avg       0.73      0.57      0.59     43480
weighted avg       0.83      0.86      0.83     43480




Parameters: {'optimizer': 'adam', 'num_units': 32, 'num_layers': 2, 'epochs': 5, 'batch_size': 32, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.88      0.98      0.93     37243
        True       0.59      0.17      0.27      6237

    accuracy                           0.86     43480
   macro avg       0.73      0.58      0.60     43480
weighted avg       0.84      0.86      0.83     43480




Parameters: {'optimizer': 'adam', 'num_units': 32, 'num_layers': 1, 'epochs': 5, 'batch_size': 16, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.88      0.98      0.92     37243
        True       0.58      0.18      0.27      6237

    accuracy                           0.86     43480
   macro avg       0.73      0.58      0.60     43480
weighted avg       0.83      0.86      0.83     43480




Parameters: {'optimizer': 'sgd', 'num_units': 64, 'num_layers': 1, 'epochs': 5, 'batch_size': 64, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.87      0.98      0.92     37243
        True       0.59      0.16      0.25      6237

    accuracy                           0.86     43480
   macro avg       0.73      0.57      0.59     43480
weighted avg       0.83      0.86      0.83     43480




Parameters: {'optimizer': 'adam', 'num_units': 32, 'num_layers': 1, 'epochs': 5, 'dropout': 0.2, 'batch_size': 64, 'activation': 'relu'}
Parameters: {'optimizer': 'adam', 'num_units': 32, 'num_layers': 1, 'epochs': 5, 'dropout': 0.2, 'batch_size': 64, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.94      0.71      0.81     37243
        True       0.30      0.73      0.42      6237

    accuracy                           0.71     43480
   macro avg       0.62      0.72      0.62     43480
weighted avg       0.85      0.71      0.75     43480




Parameters: {'optimizer': 'adam', 'num_units': 64, 'num_layers': 1, 'epochs': 5, 'dropout': 0.2, 'batch_size': 64, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.94      0.73      0.82     37243
        True       0.31      0.72      0.43      6237

    accuracy                           0.73     43480
   macro avg       0.62      0.72      0.62     43480
weighted avg       0.85      0.73      0.76     43480




Parameters: {'optimizer': 'adam', 'num_units': 32, 'num_layers': 2, 'epochs': 5, 'dropout': 0.2, 'batch_size': 64, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.94      0.75      0.83     37243
        True       0.32      0.71      0.44      6237

    accuracy                           0.74     43480
   macro avg       0.63      0.73      0.64     43480
weighted avg       0.85      0.74      0.78     43480




Parameters: {'optimizer': 'adam', 'num_units': 64, 'num_layers': 2, 'epochs': 5, 'dropout': 0.2, 'batch_size': 64, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.94      0.74      0.83     37243
        True       0.31      0.72      0.44      6237

    accuracy                           0.73     43480
   macro avg       0.63      0.73      0.63     43480
weighted avg       0.85      0.73      0.77     43480




Parameters: {'optimizer': 'adam', 'num_units': 32, 'num_layers': 1, 'epochs': 5, 'dropout': 0.5, 'batch_size': 64, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.94      0.72      0.82     37243
        True       0.31      0.73      0.43      6237

    accuracy                           0.72     43480
   macro avg       0.62      0.73      0.62     43480
weighted avg       0.85      0.72      0.76     43480




Parameters: {'optimizer': 'adam', 'num_units': 64, 'num_layers': 1, 'epochs': 5, 'dropout': 0.5, 'batch_size': 64, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.94      0.73      0.82     37243
        True       0.31      0.72      0.43      6237

    accuracy                           0.73     43480
   macro avg       0.62      0.73      0.63     43480
weighted avg       0.85      0.73      0.77     43480




Parameters: {'optimizer': 'adam', 'num_units': 32, 'num_layers': 2, 'epochs': 5, 'dropout': 0.5, 'batch_size': 64, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.94      0.71      0.81     37243
        True       0.30      0.74      0.42      6237

    accuracy                           0.71     43480
   macro avg       0.62      0.72      0.62     43480
weighted avg       0.85      0.71      0.75     43480




Parameters: {'optimizer': 'adam', 'num_units': 64, 'num_layers': 2, 'epochs': 5, 'dropout': 0.5, 'batch_size': 64, 'activation': 'relu'}
              precision    recall  f1-score   support

       False       0.94      0.71      0.81     37243
        True       0.30      0.75      0.43      6237

    accuracy                           0.72     43480
   macro avg       0.62      0.73      0.62     43480
weighted avg       0.85      0.72      0.76     43480




